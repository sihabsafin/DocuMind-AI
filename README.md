# ğŸ“„ DocuMind AI

**Enterprise-grade AI Summarization & Research Platform**

> AI summarization for serious documents â€” accurate, structured, and scalable.

[![Built with Streamlit](https://img.shields.io/badge/Built%20with-Streamlit-FF4B4B)](https://streamlit.io)
[![Powered by Groq](https://img.shields.io/badge/Powered%20by-Groq-0066FF)](https://groq.com)
[![LangChain](https://img.shields.io/badge/LangChain-Enabled-00A67E)](https://langchain.com)

---

## ğŸŒŸ Features

### Core Capabilities
- **ğŸ“š Multi-Format Support**: PDF, DOCX, TXT, Markdown
- **ğŸ§  Intelligent Strategy Selection**: Automatic Stuff/Map-Reduce/Refine selection
- **ğŸ“Š Structure-Aware Processing**: Preserves document sections and hierarchy
- **ğŸ¯ Multi-Level Summaries**: TL;DR, Bullet Points, Executive, Detailed
- **âœ¨ Style Customization**: Technical, Simple, Executive, Academic, Legal tones
- **âš¡ Lightning Fast**: Powered by Groq's high-performance inference

### Advanced Features
- **ğŸ” Section-Specific Summarization**: Target specific document sections
- **ğŸ“ Multi-Document Processing**: Summarize multiple documents together
- **ğŸ”„ Version Comparison**: Track changes between document versions
- **ğŸŒ Research Agent**: Search â†’ Summarize pipeline with web integration
- **ğŸ’¾ Export Options**: Markdown, Plain Text, JSON formats

### Enterprise-Grade
- **ğŸ“ˆ Scalable Architecture**: Handle 100+ page documents
- **ğŸ¨ Professional UI**: Modern, clean interface
- **ğŸ” Safe & Reliable**: Hallucination detection, confidence scoring
- **ğŸ’° Cost-Efficient**: Free/open-source LLMs (Groq, Ollama)

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Groq API Key (free at [console.groq.com](https://console.groq.com))
- Optional: Ollama for local models

### Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd documind-ai
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment**
```bash
cp .env.example .env
# Edit .env and add your GROQ_API_KEY
```

5. **Run the application**
```bash
streamlit run app.py
```

The application will open at `http://localhost:8501`

---

## ğŸ“– Usage Guide

### Basic Workflow

1. **Upload Document**
   - Drag and drop or browse for your document
   - Supports PDF, DOCX, TXT, Markdown

2. **Configure Settings** (Sidebar)
   - Choose AI model (Gemma-2, LLaMA-3, etc.)
   - Select summary style
   - Adjust quality vs speed preference

3. **Process & Summarize**
   - Click "Process & Summarize"
   - Watch real-time progress
   - View document analysis

4. **Review Summaries**
   - **TL;DR**: Quick 1-2 sentence overview
   - **Bullet Points**: Key points in structured format
   - **Executive Summary**: Professional business overview
   - **Detailed Summary**: Comprehensive analysis

5. **Export Results**
   - Download as Markdown, Text, or JSON
   - Share with team or integrate with workflows

### Advanced Features

#### Section-Specific Summarization
```python
# Coming soon in UI
# Currently available via API
summarizer.summarize_section("Methodology")
```

#### Multi-Document Processing
```python
# Coming soon
# Combine and compare multiple documents
```

#### Custom Styles
- **Technical**: Precise language for technical audiences
- **Simple**: Clear language for general readers
- **Executive**: Business-focused insights
- **Academic**: Scholarly tone with citations
- **Legal**: Formal legal language

---

## ğŸ—ï¸ Architecture

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Streamlit Frontend              â”‚
â”‚  (Modern UI with Real-time Updates)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Document Ingestion Layer           â”‚
â”‚  PDF | DOCX | TXT | Markdown Parser    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Text Processing & Structuring         â”‚
â”‚  Section Detection | Table Extraction   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Intelligent Chunking Engine          â”‚
â”‚  Dynamic Size | Token-Aware | Smart     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Strategy Selector                  â”‚
â”‚  Stuff | Map-Reduce | Refine           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      LLM Router (Groq/Ollama)          â”‚
â”‚  Gemma-2 | LLaMA-3 | Mixtral          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Multi-Level Summarization            â”‚
â”‚  TL;DR | Bullet | Executive | Detailed â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Export & Storage Layer              â”‚
â”‚  MD | TXT | JSON | Future: DB          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

#### 1. Document Processors (`src/processors/`)
- `PDFProcessor`: pdfplumber + PyPDF2 fallback
- `DOCXProcessor`: python-docx with structure preservation
- `TextProcessor`: TXT and Markdown with section detection

#### 2. Chunking Engine (`src/core/`)
- Smart section-aware chunking
- Dynamic chunk size optimization
- Token counting with tiktoken
- Context-preserving overlap

#### 3. Summarization Strategies (`src/strategies/`)
- **Stuff Chain**: For short documents (<4K tokens)
- **Map-Reduce Chain**: For long documents (4K-100K tokens)
- **Refine Chain**: For premium quality summaries

#### 4. LLM Manager (`src/models/`)
- Model routing and caching
- Groq integration (Gemma-2, LLaMA-3)
- Ollama support for local models
- Cost estimation framework

---

## ğŸ”§ Configuration

### Environment Variables

```env
# Required
GROQ_API_KEY=your_groq_api_key

# Model Selection
DEFAULT_MODEL=gemma2-9b-it
PREMIUM_MODEL=llama-3.1-70b-versatile
FAST_MODEL=llama-3.1-8b-instant

# Processing Settings
MAX_FILE_SIZE_MB=50
MAX_PAGES=1000
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Features
ENABLE_MULTI_DOCUMENT=true
ENABLE_SEARCH_AGENT=true
ENABLE_VERSION_COMPARISON=true
```

### Model Options

| Model | Provider | Speed | Quality | Context | Cost |
|-------|----------|-------|---------|---------|------|
| gemma2-9b-it | Groq | Fast | Good | 8K | Free |
| llama-3.1-70b-versatile | Groq | Medium | Excellent | 8K | Free |
| llama-3.1-8b-instant | Groq | Very Fast | Good | 8K | Free |
| mixtral:8x7b | Ollama | Slow | Excellent | 32K | Free (Local) |

---

## ğŸ“Š Performance

### Benchmarks

- **Short Documents** (<10 pages): ~5-10 seconds
- **Medium Documents** (10-50 pages): ~15-30 seconds
- **Long Documents** (50-100 pages): ~30-60 seconds
- **Very Long Documents** (100+ pages): ~1-3 minutes

*Tested with Groq's gemma2-9b-it model*

### Optimization

- Parallel processing with Map-Reduce
- Intelligent caching
- Token-aware chunking
- Model routing (fast â†’ default â†’ premium)

---

## ğŸ›£ï¸ Roadmap

### Phase 1: âœ… Core Platform (Current)
- [x] Multi-format document processing
- [x] Intelligent chunking
- [x] Multi-level summarization
- [x] Style customization
- [x] Streamlit UI
- [x] Export functionality

### Phase 2: ğŸš§ Advanced Features (Next)
- [ ] Section-specific summarization UI
- [ ] Multi-document processing
- [ ] Version comparison
- [ ] Research agent with web search
- [ ] Project workspace

### Phase 3: ğŸ“… Enterprise Features
- [ ] User authentication
- [ ] Team collaboration
- [ ] API endpoints
- [ ] Database storage
- [ ] Usage analytics
- [ ] Custom model fine-tuning

### Phase 4: ğŸ“… Integrations
- [ ] Notion integration
- [ ] Google Drive sync
- [ ] Slack bot
- [ ] API webhooks
- [ ] Chrome extension

---

## ğŸ§ª Testing

```bash
# Run tests
pytest tests/

# Run with coverage
pytest --cov=src tests/

# Run specific test
pytest tests/test_processors.py
```

---

## ğŸ“ API Usage (Future)

```python
from documind import DocuMind

# Initialize
dm = DocuMind(api_key="your_groq_key")

# Process document
result = dm.summarize(
    file_path="document.pdf",
    summary_type="executive",
    style="technical"
)

# Multi-document
results = dm.summarize_multiple(
    files=["doc1.pdf", "doc2.pdf"],
    compare=True
)
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see LICENSE file for details.

---

## ğŸ™ Acknowledgments

- **Groq** for lightning-fast inference
- **LangChain** for chain orchestration
- **Streamlit** for the amazing UI framework
- **Anthropic** for inspiration and best practices

---


---

## â­ Star History

If you find this project useful, please consider giving it a star! â­

---

**Built with â¤ï¸ for the AI community**

*Making document intelligence accessible to everyone*
